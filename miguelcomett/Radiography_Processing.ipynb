{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Root Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def merge_files(directory, starts_with, output_name):\n",
    "\n",
    "    file_list = []\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.root') and not file.startswith('merge') and not file.startswith(output_name):\n",
    "            if not starts_with == '' and file.startswith(starts_with):\n",
    "                    file_list.append(os.path.join(directory, file))\n",
    "            else:\n",
    "                file_list.append(os.path.join(directory, file))\n",
    "    \n",
    "    merged_file = os.path.join(directory, output_name)\n",
    "    \n",
    "    counter = 0\n",
    "    while True:\n",
    "        if not os.path.exists(f\"{merged_file}{counter}.root\"):\n",
    "            merged_file = f\"{merged_file}{counter}.root\"\n",
    "            break\n",
    "        counter = counter + 1\n",
    "\n",
    "    with uproot.recreate(merged_file) as f_out:\n",
    "        data_dict = {}  # Dictionary to store merged data temporarily\n",
    "        \n",
    "        for file in file_list:\n",
    "            \n",
    "            with uproot.open(file) as f_in:\n",
    "                for key in f_in.keys():\n",
    "                    obj = f_in[key]\n",
    "                    \n",
    "                    if isinstance(obj, uproot.TTree):\n",
    "                        new_data = obj.arrays(library=\"np\")\n",
    "                        \n",
    "                        # Extract base key name (ignore cycle numbers)\n",
    "                        base_key = key.split(';')[0]\n",
    "\n",
    "                        # If base_key is already in data_dict, concatenate data\n",
    "                        if base_key in data_dict:\n",
    "                            existing_data = data_dict[base_key]\n",
    "                            combined_data = {k: np.concatenate([existing_data[k], new_data[k]]) for k in new_data.keys() if k in existing_data}\n",
    "                            # Update with the combined data\n",
    "                            data_dict[base_key] = {**existing_data, **combined_data}\n",
    "                        else:\n",
    "                            # If base_key is not in data_dict, add new data\n",
    "                            data_dict[base_key] = new_data\n",
    "\n",
    "        for key, data in data_dict.items():\n",
    "            f_out[key] = data\n",
    "\n",
    "\n",
    "    print(\"Merged files into\", merged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'BUILD/ROOT'\n",
    "starts_with = 'root'\n",
    "output_name = 'merge'\n",
    "\n",
    "merge_files(directory, starts_with, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import os\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def root_to_dask(directory, root_name_starts, tree_name, x_branch, y_branch, decimal_places):\n",
    "    \n",
    "    file_name = os.path.join(directory, root_name_starts + \".root\")\n",
    "\n",
    "    with uproot.open(file_name) as root_file:\n",
    "        tree = root_file[tree_name]\n",
    "        if tree is None:\n",
    "            print(f\"Tree '{tree_name}' not found in {file_name}\")\n",
    "            return\n",
    "\n",
    "        x_values = tree[x_branch].array(library=\"np\") if x_branch in tree else None\n",
    "        y_values = tree[y_branch].array(library=\"np\") if y_branch in tree else None\n",
    "\n",
    "        if x_values is not None:\n",
    "            x_values = np.round(x_values, decimal_places)\n",
    "        if y_values is not None:\n",
    "            y_values = np.round(y_values, decimal_places)\n",
    "\n",
    "        if x_values is None or y_values is None:\n",
    "            print(f\"Could not retrieve data for branches {x_branch} or {y_branch}\")\n",
    "            return\n",
    "\n",
    "        x_dask_array = da.from_array(x_values, chunks=\"auto\")\n",
    "        y_dask_array = da.from_array(y_values, chunks=\"auto\")\n",
    "\n",
    "        dask_df = dd.from_dask_array(da.stack([x_dask_array, y_dask_array], axis=1), columns=[x_branch, y_branch])\n",
    "        \n",
    "        return dask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'RESULTS/'\n",
    "root_name_starts = \"arm_80kev_20M\"\n",
    "\n",
    "tree_name = \"Photons\"\n",
    "x_branch  = \"X_axis\"\n",
    "y_branch  = \"Y_axis\"\n",
    "z_branch  = \"\"\n",
    "\n",
    "decimal_places = 2\n",
    "\n",
    "dataframe = root_to_dask(directory, root_name_starts, tree_name, x_branch, y_branch, decimal_places)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Dataframe to Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def heatmap_array_dask(dataframe, x_branch, y_branch, size, num, save_as):\n",
    "\n",
    "    x_data = dataframe[x_branch].to_dask_array(lengths=True).compute()\n",
    "    y_data = dataframe[y_branch].to_dask_array(lengths=True).compute()\n",
    "\n",
    "    set_bins = np.arange(-size, size + 1, size/num)\n",
    "    heatmap, x_edges, y_edges = np.histogram2d(x_data, y_data, bins = [set_bins, set_bins])\n",
    "    heatmap = heatmap.T\n",
    "    # print(heatmap.shape)\n",
    "\n",
    "    row = len(set_bins) // 2\n",
    "    normal_map = 1 - heatmap / np.max(heatmap)\n",
    "    # plt.plot(normal_map[:][row])\n",
    "    maxi = np.max(normal_map[:5])\n",
    "    maxi = maxi * 1.2\n",
    "    print('altura de ruido:', round(maxi, 4))\n",
    "    normal_map[normal_map < maxi] = 0\n",
    "\n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.imshow(normal_map, cmap='gray', extent = [x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.plot(normal_map[:][row])\n",
    "    \n",
    "    plt.imshow(normal_map, cmap='gray', extent = [x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "    plt.savefig('Results/' + save_as, dpi = 900)\n",
    "\n",
    "    return normal_map, x_edges, y_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataframe\n",
    "\n",
    "x_branch = \"X_axis\"\n",
    "y_branch = 'Y_axis'\n",
    "\n",
    "size = 100\n",
    "bins = 80\n",
    "\n",
    "save_as = '1.jpg'\n",
    "\n",
    "htmp_array, xlim, ylim = heatmap_array_dask(data, x_branch, y_branch, size, bins, save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate Noise by Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft2, fftshift, ifft2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "def Denoise(htmp_array, hann, alpha):\n",
    "\n",
    "    image = htmp_array\n",
    "\n",
    "    fft_image = fft2(image)\n",
    "    fft_image = fftshift(fft_image)\n",
    "\n",
    "    rows, cols = image.shape\n",
    "\n",
    "    hann = False\n",
    "    if hann == True:\n",
    "    \n",
    "        l = rows * alpha\n",
    "        a = np.hanning(l)\n",
    "        b = np.hanning(l)\n",
    "\n",
    "        padding_size = rows - len(a)\n",
    "        left_padding = padding_size // 2\n",
    "        right_padding = padding_size - left_padding\n",
    "        a = np.pad(a, (left_padding, right_padding), mode='constant')\n",
    "\n",
    "        padding_size = cols - len(b)\n",
    "        left_padding = padding_size // 2\n",
    "        right_padding = padding_size - left_padding\n",
    "        b = np.pad(b, (left_padding, right_padding), mode='constant')\n",
    "\n",
    "        window = np.outer(a, b)\n",
    "\n",
    "    else:\n",
    "\n",
    "        a = signal.windows.tukey(rows, alpha)\n",
    "        b = signal.windows.tukey(rows, alpha)\n",
    "        window = np.outer(a, b)\n",
    "\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(a)\n",
    "\n",
    "    fft_image_2 = fft_image * (window)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(np.abs((fft_image_2[:][rows//2])))\n",
    "\n",
    "    fft_image = fftshift(fft_image_2)\n",
    "    fft_image = (ifft2(fft_image))\n",
    "    fft_image = (np.abs(fft_image))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Filtered Image')\n",
    "    plt.imshow(fft_image, cmap='gray')\n",
    "    # plt.savefig('Results/four1.jpg', dpi = 300)\n",
    "    plt.show()\n",
    "\n",
    "    print(fft_image.shape)\n",
    "    plt.plot(fft_image[:][60])\n",
    "\n",
    "    return fft_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hann = False\n",
    "alpha = .4\n",
    "array = htmp_array\n",
    "fft_image = Denoise(array, hann, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise with Skimage.Denoise_Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_bilateral\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = htmp_array\n",
    "denoised_image = denoise_bilateral(image, sigma_color = 0.03, sigma_spatial = 1, channel_axis = None)\n",
    "\n",
    "# Display the original and denoised images\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# ax[0].imshow(image, cmap='gray')\n",
    "# ax[0].set_title('Original Image')\n",
    "# ax[0].axis('off')\n",
    "\n",
    "# ax[1].imshow(denoised_image, cmap='gray')\n",
    "# ax[1].set_title('Denoised Image')\n",
    "# ax[1].axis('off')\n",
    "\n",
    "plt.imshow(denoised_image, cmap='gray')\n",
    "plt.savefig('denoised_image.png', dpi = 900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Plotly Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "def heatmap2(array, xlim, ylim, title, x_label, y_label, width, height, save_as):\n",
    "\n",
    "    fig = go.Figure(go.Heatmap(\n",
    "                    z = array,\n",
    "                    x = xlim,\n",
    "                    y = ylim,\n",
    "                    colorscale = [[0, 'black'], [1, 'white']],  # Grayscale from black to white\n",
    "                    colorbar = dict(title = \"Density\", tickfont = dict(family = 'Merriweather', size = 16, color = 'Black'))))\n",
    "    \n",
    "    font_family = 'Merriweather'\n",
    "    font_small  = 16\n",
    "    font_medium = 20\n",
    "    font_large  = 18\n",
    "    \n",
    "    fig.update_layout(\n",
    "                    title = dict(text = title, font = dict(family = font_family, size = font_large, color = \"Black\"), \n",
    "                                 x = 0.51, y = 0.93, yanchor = 'middle', xanchor = 'center'),\n",
    "                    xaxis_title = dict(text = x_label, font = dict(family = font_family, size = font_medium, color = \"Black\")),\n",
    "                    yaxis_title = dict(text = y_label, font = dict(family = font_family, size = font_medium, color = \"Black\")),\n",
    "                    xaxis = dict(tickfont = dict(family = font_family, size = font_small, color = \"Black\"), title_standoff = 25),\n",
    "                    yaxis = dict(tickfont = dict(family = font_family, size = font_small, color = \"Black\"), title_standoff = 10),\n",
    "                    width  = width,\n",
    "                    height = height,\n",
    "                    margin = dict(l = 105, r = 90, t = 90, b = 90)\n",
    "    )\n",
    "    \n",
    "    pio.write_image(fig, save_as, width = width, height = height, scale = 5)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = htmp_array\n",
    "array = denoised_image\n",
    "# array = fft_image\n",
    "\n",
    "title   = r\"$ \\large{ \\text{Denoised Healthy Bone, 80keV, 20M Beams,} }, \\ \\normalsize{ \\theta = 0Â° } $\"\n",
    "x_label = r\"$ \\large{ \\text{X Axis} \\ (mm)} $\"\n",
    "y_label = r\"$ \\large{ \\text{Y Axis} \\ (mm)} $\"\n",
    "\n",
    "width  = 800\n",
    "height = 800\n",
    "\n",
    "save_as = 'Results/test.jpg'\n",
    "\n",
    "heatmap2(array, xlim, ylim, title, x_label, y_label, width, height, save_as)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
