{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Root Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def merge_files(directory, starts_with, output_name):\n",
    "\n",
    "    file_list = []\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.root') and not file.startswith('merge') and not file.startswith(output_name):\n",
    "            if not starts_with == '' and file.startswith(starts_with):\n",
    "                    file_list.append(os.path.join(directory, file))\n",
    "            else:\n",
    "                file_list.append(os.path.join(directory, file))\n",
    "    \n",
    "    merged_file = os.path.join(directory, output_name)\n",
    "    \n",
    "    counter = 0\n",
    "    while True:\n",
    "        if not os.path.exists(f\"{merged_file}{counter}.root\"):\n",
    "            merged_file = f\"{merged_file}{counter}.root\"\n",
    "            break\n",
    "        counter = counter + 1\n",
    "\n",
    "    with uproot.recreate(merged_file) as f_out:\n",
    "        data_dict = {}  # Dictionary to store merged data temporarily\n",
    "        \n",
    "        for file in file_list:\n",
    "            \n",
    "            with uproot.open(file) as f_in:\n",
    "                for key in f_in.keys():\n",
    "                    obj = f_in[key]\n",
    "                    \n",
    "                    if isinstance(obj, uproot.TTree):\n",
    "                        new_data = obj.arrays(library=\"np\")\n",
    "                        \n",
    "                        # Extract base key name (ignore cycle numbers)\n",
    "                        base_key = key.split(';')[0]\n",
    "\n",
    "                        # If base_key is already in data_dict, concatenate data\n",
    "                        if base_key in data_dict:\n",
    "                            existing_data = data_dict[base_key]\n",
    "                            combined_data = {k: np.concatenate([existing_data[k], new_data[k]]) for k in new_data.keys() if k in existing_data}\n",
    "                            # Update with the combined data\n",
    "                            data_dict[base_key] = {**existing_data, **combined_data}\n",
    "                        else:\n",
    "                            # If base_key is not in data_dict, add new data\n",
    "                            data_dict[base_key] = new_data\n",
    "\n",
    "        for key, data in data_dict.items():\n",
    "            f_out[key] = data\n",
    "\n",
    "\n",
    "    print(\"Merged files into\", merged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'BUILD/ROOT'\n",
    "starts_with = 'root'\n",
    "output_name = 'merge'\n",
    "\n",
    "merge_files(directory, starts_with, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import os\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def root_to_dask(directory, root_name_starts, tree_name, x_branch, y_branch, decimal_places):\n",
    "    \n",
    "    file_name = os.path.join(directory, root_name_starts + \".root\")\n",
    "\n",
    "    with uproot.open(file_name) as root_file:\n",
    "        tree = root_file[tree_name]\n",
    "        if tree is None:\n",
    "            print(f\"Tree '{tree_name}' not found in {file_name}\")\n",
    "            return\n",
    "\n",
    "        x_values = tree[x_branch].array(library=\"np\") if x_branch in tree else None\n",
    "        y_values = tree[y_branch].array(library=\"np\") if y_branch in tree else None\n",
    "\n",
    "        if x_values is not None:\n",
    "            x_values = np.round(x_values, decimal_places)\n",
    "        if y_values is not None:\n",
    "            y_values = np.round(y_values, decimal_places)\n",
    "\n",
    "        if x_values is None or y_values is None:\n",
    "            print(f\"Could not retrieve data for branches {x_branch} or {y_branch}\")\n",
    "            return\n",
    "\n",
    "        x_dask_array = da.from_array(x_values, chunks=\"auto\")\n",
    "        y_dask_array = da.from_array(y_values, chunks=\"auto\")\n",
    "\n",
    "        dask_df = dd.from_dask_array(da.stack([x_dask_array, y_dask_array], axis=1), columns=[x_branch, y_branch])\n",
    "        \n",
    "        return dask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'RESULTS/'\n",
    "root_name_starts = \"80kev_500M\"\n",
    "\n",
    "tree_name = \"Photons\"\n",
    "x_branch  = \"X_axis\"\n",
    "y_branch  = \"Y_axis\"\n",
    "\n",
    "tree_name = \"G4_PCM\"\n",
    "x_branch  = \"PositionX\"\n",
    "y_branch  = \"PositionY\"\n",
    "\n",
    "z_branch  = \"\"\n",
    "\n",
    "decimal_places = 2\n",
    "\n",
    "dataframe = root_to_dask(directory, root_name_starts, tree_name, x_branch, y_branch, decimal_places)\n",
    "\n",
    "x_branch = \"X_axis\"\n",
    "y_branch = 'Y_axis'\n",
    "\n",
    "x_branch = 'PositionX'\n",
    "y_branch = 'PositionY'\n",
    "\n",
    "x_data = dataframe[x_branch].to_dask_array(lengths=True)\n",
    "y_data = dataframe[y_branch].to_dask_array(lengths=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Dataframe to Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def heatmap_array_dask(x_data, y_data, size, num, save_as):\n",
    "\n",
    "    set_bins = np.arange(-size, size + 1, size/num)\n",
    "    # heatmap, x_edges, y_edges = np.histogram2d(x_data, y_data, bins = [set_bins, set_bins])\n",
    "    heatmap, x_edges, y_edges = da.histogram2d(x_data, y_data, bins = [set_bins, set_bins])\n",
    "    heatmap = heatmap.T\n",
    "\n",
    "    heatmap = heatmap.compute()  \n",
    "    x_edges = x_edges.compute()  \n",
    "    y_edges = y_edges.compute()\n",
    "\n",
    "    normal_map = 1 - heatmap / np.max(heatmap)\n",
    "\n",
    "    columns = heatmap.shape[1]\n",
    "    column_i = int(columns * 0.1)\n",
    "    column_j = int(columns * 0.9)\n",
    "\n",
    "    rows = heatmap.shape[0]\n",
    "    row_i = int(rows * 0.01)\n",
    "    row_j = int(rows * 0.1)\n",
    "\n",
    "    maxi = np.max(normal_map[row_i:row_j, column_i:column_j])\n",
    "    maxi = maxi * 1.15\n",
    "    # print('altura de ruido:', round(maxi, 4))\n",
    "\n",
    "    normal_map[normal_map < maxi] = 0\n",
    "\n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.imshow(normal_map, cmap='gray', extent = [x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.plot(normal_map[:][110])\n",
    "    \n",
    "    plt.imshow(normal_map, cmap='gray', extent = [x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "    if save_as != '': plt.savefig('Results/' + save_as + '.jpg', dpi = 900)\n",
    "\n",
    "    return normal_map, x_edges, y_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "bins = 30\n",
    "\n",
    "save_as = ''\n",
    "\n",
    "htmp_array, xlim, ylim = heatmap_array_dask(x_data, y_data, size, bins, save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate Noise by Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft2, fftshift, ifft2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "def Denoise(htmp_array, hann, alpha):\n",
    "\n",
    "    image = htmp_array\n",
    "\n",
    "    fft_image = fft2(image)\n",
    "    fft_image = fftshift(fft_image)\n",
    "\n",
    "    rows, cols = image.shape\n",
    "\n",
    "    hann = False\n",
    "    if hann == True:\n",
    "    \n",
    "        l = rows * alpha\n",
    "        a = np.hanning(l)\n",
    "        b = np.hanning(l)\n",
    "\n",
    "        padding_size = rows - len(a)\n",
    "        left_padding = padding_size // 2\n",
    "        right_padding = padding_size - left_padding\n",
    "        a = np.pad(a, (left_padding, right_padding), mode='constant')\n",
    "\n",
    "        padding_size = cols - len(b)\n",
    "        left_padding = padding_size // 2\n",
    "        right_padding = padding_size - left_padding\n",
    "        b = np.pad(b, (left_padding, right_padding), mode='constant')\n",
    "\n",
    "        window = np.outer(a, b)\n",
    "\n",
    "    else:\n",
    "\n",
    "        a = signal.windows.tukey(rows, alpha)\n",
    "        b = signal.windows.tukey(rows, alpha)\n",
    "        window = np.outer(a, b)\n",
    "\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(a)\n",
    "\n",
    "    fft_image_2 = fft_image * (window)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(np.abs((fft_image_2[:][rows//2])))\n",
    "\n",
    "    fft_image = fftshift(fft_image_2)\n",
    "    fft_image = (ifft2(fft_image))\n",
    "    fft_image = (np.abs(fft_image))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Filtered Image')\n",
    "    plt.imshow(fft_image, cmap='gray')\n",
    "    # plt.savefig('Results/four1.jpg', dpi = 300)\n",
    "    plt.show()\n",
    "\n",
    "    print(fft_image.shape)\n",
    "    plt.plot(fft_image[:][60])\n",
    "\n",
    "    return fft_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hann = False\n",
    "alpha = .4\n",
    "array = htmp_array\n",
    "fft_image = Denoise(array, hann, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise with Skimage.Denoise_Bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_bilateral\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = htmp_array\n",
    "denoised_image = denoise_bilateral(image, sigma_color = 0.03, sigma_spatial = 1, channel_axis = None)\n",
    "\n",
    "# Display the original and denoised images\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# ax[0].imshow(image, cmap='gray')\n",
    "# ax[0].set_title('Original Image')\n",
    "# ax[0].axis('off')\n",
    "\n",
    "# ax[1].imshow(denoised_image, cmap='gray')\n",
    "# ax[1].set_title('Denoised Image')\n",
    "# ax[1].axis('off')\n",
    "\n",
    "plt.imshow(denoised_image, cmap='gray')\n",
    "plt.savefig('denoised_image.png', dpi = 900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Plotly Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "def heatmap2(array, xlim, ylim, title, x_label, y_label, width, height, save_as):\n",
    "\n",
    "    fig = go.Figure(go.Heatmap(z = array, x = xlim, y = ylim,\n",
    "                                colorscale = [[0, 'black'], [1, 'white']], \n",
    "                                colorbar = dict(title = \"Density\", tickfont = dict(family = 'Merriweather', size = 16, color = 'Black'))))\n",
    "    \n",
    "    font_family = 'Merriweather'\n",
    "    font_small  = 16\n",
    "    font_medium = 20\n",
    "    font_large  = 18\n",
    "    \n",
    "    fig.update_layout(\n",
    "                    title = dict(text = title, font = dict(family = font_family, size = font_large, color = \"Black\"), \n",
    "                                 x = 0.51, y = 0.93, yanchor = 'middle', xanchor = 'center'),\n",
    "                    xaxis_title = dict(text = x_label, font = dict(family = font_family, size = font_medium, color = \"Black\")),\n",
    "                    yaxis_title = dict(text = y_label, font = dict(family = font_family, size = font_medium, color = \"Black\")),\n",
    "                    xaxis = dict(tickfont = dict(family = font_family, size = font_small, color = \"Black\"), title_standoff = 25),\n",
    "                    yaxis = dict(tickfont = dict(family = font_family, size = font_small, color = \"Black\"), title_standoff = 10),\n",
    "                    width  = width,\n",
    "                    height = height,\n",
    "                    margin = dict(l = 105, r = 90, t = 90, b = 90)\n",
    "    )\n",
    "   \n",
    "    if save_as != '': pio.write_image(fig, 'Results/' + save_as + '.jpg', width = width, height = height, scale = 5)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = htmp_array\n",
    "# array = denoised_image\n",
    "# array = fft_image\n",
    "\n",
    "title   = r\"$ \\large{ \\text{Healthy Bone, 80keV, 250M Beams,} } \\ \\normalsize{ \\theta = 0° } $\"\n",
    "x_label = r\"$ \\large{ \\text{X Axis} \\ (mm)} $\"\n",
    "y_label = r\"$ \\large{ \\text{Y Axis} \\ (mm)} $\"\n",
    "\n",
    "width  = 800\n",
    "height = 800\n",
    "\n",
    "save_as = ''\n",
    "\n",
    "heatmap2(array, xlim, ylim, title, x_label, y_label, width, height, save_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Fixed CNR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def CNR(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    cropped_image = image.crop((520, 450, image.width - 580, image.width - 440))\n",
    "    data = np.array(cropped_image)\n",
    "\n",
    "    plt.imshow(data)\n",
    "\n",
    "    signal_avg = 0\n",
    "    background_avg = 0\n",
    "    background_std = 0\n",
    "\n",
    "    x1_signal = 1160\n",
    "    y1_signal = 1130\n",
    "    x2_signal = 1740\n",
    "    y2_signal = 1980\n",
    "\n",
    "    plt.gca().add_patch(plt.Rectangle((x1_signal, y1_signal), x2_signal - x1_signal, y2_signal - y1_signal, \n",
    "                                    linewidth=2, edgecolor='yellow', facecolor='none'))\n",
    "\n",
    "\n",
    "    if x2_signal > x1_signal:\n",
    "        if y2_signal > y1_signal:\n",
    "            signal = data[round(y1_signal):round(y2_signal), round(x1_signal):round(x2_signal)]\n",
    "        else:\n",
    "            signal = data[round(y2_signal):round(y1_signal), round(x1_signal):round(x2_signal)]\n",
    "    else:\n",
    "        if y2_signal > y1_signal:\n",
    "            signal = data[round(y1_signal):round(y2_signal), round(x2_signal):round(x1_signal)]\n",
    "        else:\n",
    "            signal = data[round(y2_signal):round(y1_signal), round(x2_signal):round(x1_signal)]\n",
    "\n",
    "    signal_avg = np.average(signal)\n",
    "    print(\"Signal avg: \"+str(signal_avg))\n",
    "\n",
    "    x1_background = 1790\n",
    "    y1_background = 1130\n",
    "    x2_background = 1940\n",
    "    y2_background = 1980\n",
    "\n",
    "    plt.gca().add_patch(plt.Rectangle((x1_background, y1_background), x2_background - x1_background, y2_background - y1_background, \n",
    "                                    linewidth=2, edgecolor='red', facecolor='none'))\n",
    "\n",
    "\n",
    "    if x2_background > x1_background:\n",
    "        if y2_background > y1_background:\n",
    "            background = data[round(y1_background):round(y2_background), round(x1_background):round(x2_background)]\n",
    "        else:\n",
    "            background = data[round(y2_background):round(y1_background), round(x1_background):round(x2_background)]\n",
    "    else:\n",
    "        if y2_background > y1_background:\n",
    "            background = data[round(y1_background):round(y2_background), round(x2_background):round(x1_background)]\n",
    "        else:\n",
    "            background = data[round(y2_background):round(y1_background), round(x2_background):round(x1_background)]\n",
    "\n",
    "    background_avg = np.average(background)\n",
    "    background_std = np.std(background)\n",
    "\n",
    "    print(\"Background avg: \"+str(background_avg))\n",
    "    print(\"Background std dev: \"+str(background_std))\n",
    "\n",
    "    cnr = (signal_avg-background_avg)/background_std\n",
    "    print(\"CNR: \", round(cnr, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"RESULTS/\" + \"\" + \"prueba2\" + \".jpg\"\n",
    "\n",
    "CNR(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
